{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file data_meg/R2487/emptyroom/R2487_emptyroom-raw.fif...\n",
      "Isotrak not found\n",
      "    Range : 0 ... 179999 =      0.000 ...   179.999 secs\n",
      "Ready.\n",
      "Reading 0 ... 179999  =      0.000 ...   179.999 secs...\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy.ma as ma\n",
    "import pandas as pd\n",
    "import mne\n",
    "import mne\n",
    "from mne.datasets import sample\n",
    "from mne.decoding import (\n",
    "    CSP,\n",
    "    GeneralizingEstimator,\n",
    "    LinearModel,\n",
    "    Scaler,\n",
    "    SlidingEstimator,\n",
    "    Vectorizer,\n",
    "    cross_val_multiscore,\n",
    "    get_coef,\n",
    ")\n",
    "data_dir = 'data_meg'\n",
    "subj = \"R2487\"\n",
    "dataqual = 'prepro' #or loc/exp\n",
    "exp = 'loc' #or exp\n",
    "dtype = \"raw\"\n",
    "label_dir = 'data_log'\n",
    "save_dir = 'data_meg'\n",
    "bad_channels_dict = {\n",
    "    \"R2490\": ['MEG 014', 'MEG 004', 'MEG 079', 'MEG 072', 'MEG 070', 'MEG 080', 'MEG 074', 'MEG 067', 'MEG 082', 'MEG 105', 'MEG 115', 'MEG 141', 'MEG 153'],\n",
    "    \"R2488\": ['MEG 015', 'MEG 014', 'MEG 068', 'MEG 079', 'MEG 146', 'MEG 147', 'MEG 007', 'MEG 141'],\n",
    "    \"R2487\": ['MEG 015', 'MEG 014', 'MEG 068', 'MEG 079', 'MEG 147', 'MEG 146', 'MEG 004'],\n",
    "    \"R2280\": ['MEG 024', 'MEG 039', 'MEG 079', 'MEG 077', 'MEG 141', 'MEG 073', 'MEG 075', 'MEG 076', 'MEG 064', 'MEG 063', 'MEG 060', 'MEG 059', 'MEG 058']\n",
    "}\n",
    "bad_channels = bad_channels_dict.get(subj, [])\n",
    "raw_empty_room = mne.io.read_raw_fif(f'{data_dir}/{subj}/emptyroom/{subj}_emptyroom-{dtype}.fif', preload=True)\n",
    "raw_empty_room.info['bads'].extend(bad_channels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file data_meg/R2487/prepro/R2487_loc.fif...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/79/m99pb_8d67l3d79st4zhf4tc0000gn/T/ipykernel_56589/2749176485.py:2: RuntimeWarning: This filename (data_meg/R2487/prepro/R2487_loc.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(f'{data_dir}/{subj}/{dataqual}/{subj}_{exp}.fif', preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Range : 0 ... 889999 =      0.000 ...   889.999 secs\n",
      "Ready.\n",
      "Reading 0 ... 889999  =      0.000 ...   889.999 secs...\n",
      "Filtering raw data in 2 contiguous segments\n",
      "Setting up band-pass filter from 1 - 40 Hz\n",
      "\n",
      "IIR filter parameters\n",
      "---------------------\n",
      "Butterworth bandpass zero-phase (two-pass forward and reverse) non-causal filter:\n",
      "- Filter order 16 (effective, after forward-backward)\n",
      "- Cutoffs at 1.00, 40.00 Hz: -6.02, -6.02 dB\n",
      "\n",
      "317 events found on stim channel STI 014\n",
      "Event IDs: [164 165]\n",
      "254 events found on stim channel STI 014\n",
      "Event IDs: [164 165]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/79/m99pb_8d67l3d79st4zhf4tc0000gn/T/ipykernel_56589/2749176485.py:7: RuntimeWarning: Resampling of the stim channels caused event information to become unreliable. Consider finding events on the original data and passing the event matrix as a parameter.\n",
      "  raw.resample(sfreq / downsample)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">\n",
       "    const toggleVisibility = (className) => {\n",
       "\n",
       "  const elements = document.querySelectorAll(`.${className}`)\n",
       "\n",
       "  elements.forEach(element => {\n",
       "    if (element.classList.contains('repr-section-header')) {\n",
       "      // Don't collapse the section header row.\n",
       "       return\n",
       "    }\n",
       "    if (element.classList.contains('repr-element-collapsed')) {\n",
       "      // Force a reflow to ensure the display change takes effect before removing the class\n",
       "      element.classList.remove('repr-element-collapsed')\n",
       "      element.offsetHeight // This forces the browser to recalculate layout\n",
       "      element.classList.remove('repr-element-faded')\n",
       "    } else {\n",
       "      // Start transition to hide the element\n",
       "      element.classList.add('repr-element-faded')\n",
       "      element.addEventListener('transitionend', handler = (e) => {\n",
       "        if (e.propertyName === 'opacity' && getComputedStyle(element).opacity === '0.2') {\n",
       "          element.classList.add('repr-element-collapsed')\n",
       "          element.removeEventListener('transitionend', handler)\n",
       "        }\n",
       "      });\n",
       "    }\n",
       "  });\n",
       "\n",
       "  // Take care of button (adjust caret)\n",
       "  const button = document.querySelectorAll(`.repr-section-header.${className} > th.repr-section-toggle-col > button`)[0]\n",
       "  button.classList.toggle('collapsed')\n",
       "\n",
       "  // Take care of the tooltip of the section header row\n",
       "  const sectionHeaderRow = document.querySelectorAll(`tr.repr-section-header.${className}`)[0]\n",
       "  sectionHeaderRow.classList.toggle('collapsed')\n",
       "  sectionHeaderRow.title = sectionHeaderRow.title === 'Hide section' ? 'Show section' : 'Hide section'\n",
       "}\n",
       "</script>\n",
       "\n",
       "<style type=\"text/css\">\n",
       "    table.repr.table.table-hover.table-striped.table-sm.table-responsive.small {\n",
       "  /* Don't make rows wider than they need to be. */\n",
       "  display: inline;\n",
       "}\n",
       "\n",
       "table > tbody > tr.repr-element > td {\n",
       "  /* Apply a tighter layout to the table cells. */\n",
       "  padding-top: 0.1rem;\n",
       "  padding-bottom: 0.1rem;\n",
       "  padding-right: 1rem;\n",
       "}\n",
       "\n",
       "table > tbody > tr > td.repr-section-toggle-col {\n",
       "  /* Remove background and border of the first cell in every row\n",
       "     (this row is only used for the collapse / uncollapse caret)\n",
       "\n",
       "     TODO: Need to find a good solution for VS Code that works in both\n",
       "           light and dark mode. */\n",
       "  border-color: transparent;\n",
       "  --bs-table-accent-bg: transparent;\n",
       "}\n",
       "\n",
       "tr.repr-section-header {\n",
       "  /* Remove stripes from section header rows */\n",
       "  background-color: transparent;\n",
       "  border-color: transparent;\n",
       "  --bs-table-striped-bg: transparent;\n",
       "  cursor: pointer;\n",
       "}\n",
       "\n",
       "tr.repr-section-header > th {\n",
       "  text-align: left !important;\n",
       "  vertical-align: middle;\n",
       "}\n",
       "\n",
       ".repr-element, tr.repr-element > td {\n",
       "  opacity: 1;\n",
       "  text-align: left !important;\n",
       "}\n",
       "\n",
       ".repr-element-faded {\n",
       "  transition: 0.3s ease;\n",
       "  opacity: 0.2;\n",
       "}\n",
       "\n",
       ".repr-element-collapsed {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "/* Collapse / uncollapse button and the caret it contains. */\n",
       ".repr-section-toggle-col button {\n",
       "  cursor: pointer;\n",
       "  width: 1rem;\n",
       "  background-color: transparent;\n",
       "  border-color: transparent;\n",
       "}\n",
       "\n",
       "span.collapse-uncollapse-caret {\n",
       "  width: 1rem;\n",
       "  height: 1rem;\n",
       "  display: block;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: left;\n",
       "  background-size: contain;\n",
       "}\n",
       "\n",
       "/* The collapse / uncollapse carets were copied from the free Font Awesome collection and adjusted. */\n",
       "\n",
       "/* Default to black carets for light mode */\n",
       ".repr-section-toggle-col > button.collapsed > span.collapse-uncollapse-caret {\n",
       "  background-image: url('data:image/svg+xml;charset=utf8,<svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 256 512\"><!--!Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free Copyright 2024 Fonticons, Inc.--><path fill=\"black\" d=\"M246.6 278.6c12.5-12.5 12.5-32.8 0-45.3l-128-128c-9.2-9.2-22.9-11.9-34.9-6.9s-19.8 16.6-19.8 29.6l0 256c0 12.9 7.8 24.6 19.8 29.6s25.7 2.2 34.9-6.9l128-128z\"/></svg>');\n",
       "}\n",
       "\n",
       ".repr-section-toggle-col\n",
       "  > button:not(.collapsed)\n",
       "  > span.collapse-uncollapse-caret {\n",
       "  background-image: url('data:image/svg+xml;charset=utf8,<svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 320 512\"><!--!Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free Copyright 2024 Fonticons, Inc.--><path fill=\"black\" d=\"M137.4 374.6c12.5 12.5 32.8 12.5 45.3 0l128-128c9.2-9.2 11.9-22.9 6.9-34.9s-16.6-19.8-29.6-19.8L32 192c-12.9 0-24.6 7.8-29.6 19.8s-2.2 25.7 6.9 34.9l128 128z\"/></svg>');\n",
       "}\n",
       "\n",
       "/* Use white carets for dark mode */\n",
       "@media (prefers-color-scheme: dark) {\n",
       "  .repr-section-toggle-col > button.collapsed > span.collapse-uncollapse-caret {\n",
       "    background-image: url('data:image/svg+xml;charset=utf8,<svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 256 512\"><!--!Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free Copyright 2024 Fonticons, Inc.--><path fill=\"white\" d=\"M246.6 278.6c12.5-12.5 12.5-32.8 0-45.3l-128-128c-9.2-9.2-22.9-11.9-34.9-6.9s-19.8 16.6-19.8 29.6l0 256c0 12.9 7.8 24.6 19.8 29.6s25.7 2.2 34.9-6.9l128-128z\"/></svg>');\n",
       "  }\n",
       "\n",
       "  .repr-section-toggle-col\n",
       "    > button:not(.collapsed)\n",
       "    > span.collapse-uncollapse-caret {\n",
       "    background-image: url('data:image/svg+xml;charset=utf8,<svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 320 512\"><!--!Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free Copyright 2024 Fonticons, Inc.--><path fill=\"white\" d=\"M137.4 374.6c12.5 12.5 32.8 12.5 45.3 0l128-128c9.2-9.2 11.9-22.9 6.9-34.9s-16.6-19.8-29.6-19.8L32 192c-12.9 0-24.6 7.8-29.6 19.8s-2.2 25.7 6.9 34.9l128 128z\"/></svg>');\n",
       "  }\n",
       "}\n",
       "\n",
       ".channel-names-btn {\n",
       "  padding: 0;\n",
       "  border: none;\n",
       "  background: none;\n",
       "  text-decoration: underline;\n",
       "  text-decoration-style: dashed;\n",
       "  cursor: pointer;\n",
       "  color: #0d6efd;\n",
       "}\n",
       "\n",
       ".channel-names-btn:hover {\n",
       "  color: #0a58ca;\n",
       "}\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "<table class=\"repr table table-hover table-striped table-sm table-responsive small\">\n",
       "    \n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "<tr class=\"repr-section-header general-6da07c22-0c2a-484d-a432-1a957cc11502\"  title=\"Hide section\" \n",
       "    onclick=\"toggleVisibility('general-6da07c22-0c2a-484d-a432-1a957cc11502')\">\n",
       "    <th class=\"repr-section-toggle-col\">\n",
       "        <button>\n",
       "            \n",
       "            <span class=\"collapse-uncollapse-caret\"></span>\n",
       "        </button>\n",
       "    </th>\n",
       "    <th colspan=\"2\">\n",
       "        <strong>General</strong>\n",
       "    </th>\n",
       "</tr>\n",
       "\n",
       "<tr class=\"repr-element general-6da07c22-0c2a-484d-a432-1a957cc11502 \">\n",
       "    <td class=\"repr-section-toggle-col\"></td>\n",
       "    <td>Filename(s)</td>\n",
       "    <td>\n",
       "        \n",
       "        R2487_loc.fif\n",
       "        \n",
       "        \n",
       "    </td>\n",
       "</tr>\n",
       "\n",
       "<tr class=\"repr-element general-6da07c22-0c2a-484d-a432-1a957cc11502 \">\n",
       "    <td class=\"repr-section-toggle-col\"></td>\n",
       "    <td>MNE object type</td>\n",
       "    <td>Raw</td>\n",
       "</tr>\n",
       "<tr class=\"repr-element general-6da07c22-0c2a-484d-a432-1a957cc11502 \">\n",
       "    <td class=\"repr-section-toggle-col\"></td>\n",
       "    <td>Measurement date</td>\n",
       "    \n",
       "    <td>2024-11-12 at 21:15:44 UTC</td>\n",
       "    \n",
       "</tr>\n",
       "<tr class=\"repr-element general-6da07c22-0c2a-484d-a432-1a957cc11502 \">\n",
       "    <td class=\"repr-section-toggle-col\"></td>\n",
       "    <td>Participant</td>\n",
       "    \n",
       "    <td>Unknown</td>\n",
       "    \n",
       "</tr>\n",
       "<tr class=\"repr-element general-6da07c22-0c2a-484d-a432-1a957cc11502 \">\n",
       "    <td class=\"repr-section-toggle-col\"></td>\n",
       "    <td>Experimenter</td>\n",
       "    \n",
       "    <td>Unknown</td>\n",
       "    \n",
       "</tr>\n",
       "    \n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "<tr class=\"repr-section-header acquisition-7c460c71-9724-4bcd-9aa6-8723843ebc48\" \n",
       "    title=\"Hide section\"  onclick=\"toggleVisibility('acquisition-7c460c71-9724-4bcd-9aa6-8723843ebc48')\">\n",
       "    <th class=\"repr-section-toggle-col\">\n",
       "        <button>\n",
       "            \n",
       "            <span class=\"collapse-uncollapse-caret\"></span>\n",
       "        </button>\n",
       "    </th>\n",
       "    <th colspan=\"2\">\n",
       "        <strong>Acquisition</strong>\n",
       "    </th>\n",
       "</tr>\n",
       "\n",
       "<tr class=\"repr-element acquisition-7c460c71-9724-4bcd-9aa6-8723843ebc48 \">\n",
       "    <td class=\"repr-section-toggle-col\"></td>\n",
       "    <td>Duration</td>\n",
       "    <td>00:14:50 (HH:MM:SS)</td>\n",
       "</tr>\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "<tr class=\"repr-element acquisition-7c460c71-9724-4bcd-9aa6-8723843ebc48 \">\n",
       "    <td class=\"repr-section-toggle-col\"></td>\n",
       "    <td>Sampling frequency</td>\n",
       "    <td>100.00 Hz</td>\n",
       "</tr>\n",
       "\n",
       "\n",
       "<tr class=\"repr-element acquisition-7c460c71-9724-4bcd-9aa6-8723843ebc48 \">\n",
       "    <td class=\"repr-section-toggle-col\"></td>\n",
       "    <td>Time points</td>\n",
       "    <td>89,000</td>\n",
       "</tr>\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "<tr class=\"repr-section-header channels-66805a13-fabb-461d-aba9-75e0d45ee18d\"  title=\"Hide section\" \n",
       "    onclick=\"toggleVisibility('channels-66805a13-fabb-461d-aba9-75e0d45ee18d')\">\n",
       "    <th class=\"repr-section-toggle-col\">\n",
       "        <button>\n",
       "            \n",
       "            <span class=\"collapse-uncollapse-caret\"></span>\n",
       "        </button>\n",
       "    </th>\n",
       "    <th colspan=\"2\">\n",
       "        <strong>Channels</strong>\n",
       "    </th>\n",
       "</tr>\n",
       "\n",
       "\n",
       "<tr class=\"repr-element channels-66805a13-fabb-461d-aba9-75e0d45ee18d \">\n",
       "    <td class=\"repr-section-toggle-col\"></td>\n",
       "    <td>Magnetometers</td>\n",
       "    <td>\n",
       "        <button class=\"channel-names-btn\" onclick=\"alert('Good Magnetometers:\\n\\nMEG&nbsp;001, MEG&nbsp;002, MEG&nbsp;003, MEG&nbsp;005, MEG&nbsp;006, MEG&nbsp;007, MEG&nbsp;008, MEG&nbsp;009, MEG&nbsp;010, MEG&nbsp;011, MEG&nbsp;012, MEG&nbsp;013, MEG&nbsp;016, MEG&nbsp;017, MEG&nbsp;018, MEG&nbsp;019, MEG&nbsp;020, MEG&nbsp;021, MEG&nbsp;022, MEG&nbsp;023, MEG&nbsp;024, MEG&nbsp;025, MEG&nbsp;026, MEG&nbsp;027, MEG&nbsp;028, MEG&nbsp;029, MEG&nbsp;030, MEG&nbsp;031, MEG&nbsp;032, MEG&nbsp;033, MEG&nbsp;034, MEG&nbsp;035, MEG&nbsp;036, MEG&nbsp;037, MEG&nbsp;038, MEG&nbsp;039, MEG&nbsp;040, MEG&nbsp;041, MEG&nbsp;042, MEG&nbsp;043, MEG&nbsp;044, MEG&nbsp;045, MEG&nbsp;046, MEG&nbsp;047, MEG&nbsp;048, MEG&nbsp;049, MEG&nbsp;050, MEG&nbsp;051, MEG&nbsp;052, MEG&nbsp;053, MEG&nbsp;054, MEG&nbsp;055, MEG&nbsp;056, MEG&nbsp;057, MEG&nbsp;058, MEG&nbsp;059, MEG&nbsp;060, MEG&nbsp;061, MEG&nbsp;062, MEG&nbsp;063, MEG&nbsp;064, MEG&nbsp;065, MEG&nbsp;066, MEG&nbsp;067, MEG&nbsp;069, MEG&nbsp;070, MEG&nbsp;071, MEG&nbsp;072, MEG&nbsp;073, MEG&nbsp;074, MEG&nbsp;075, MEG&nbsp;076, MEG&nbsp;077, MEG&nbsp;078, MEG&nbsp;080, MEG&nbsp;081, MEG&nbsp;082, MEG&nbsp;083, MEG&nbsp;084, MEG&nbsp;085, MEG&nbsp;086, MEG&nbsp;087, MEG&nbsp;088, MEG&nbsp;089, MEG&nbsp;090, MEG&nbsp;091, MEG&nbsp;092, MEG&nbsp;093, MEG&nbsp;094, MEG&nbsp;095, MEG&nbsp;096, MEG&nbsp;097, MEG&nbsp;098, MEG&nbsp;099, MEG&nbsp;100, MEG&nbsp;101, MEG&nbsp;102, MEG&nbsp;103, MEG&nbsp;104, MEG&nbsp;105, MEG&nbsp;106, MEG&nbsp;107, MEG&nbsp;108, MEG&nbsp;109, MEG&nbsp;110, MEG&nbsp;111, MEG&nbsp;112, MEG&nbsp;113, MEG&nbsp;114, MEG&nbsp;115, MEG&nbsp;116, MEG&nbsp;117, MEG&nbsp;118, MEG&nbsp;119, MEG&nbsp;120, MEG&nbsp;121, MEG&nbsp;122, MEG&nbsp;123, MEG&nbsp;124, MEG&nbsp;125, MEG&nbsp;126, MEG&nbsp;127, MEG&nbsp;128, MEG&nbsp;129, MEG&nbsp;130, MEG&nbsp;131, MEG&nbsp;132, MEG&nbsp;133, MEG&nbsp;134, MEG&nbsp;135, MEG&nbsp;136, MEG&nbsp;137, MEG&nbsp;138, MEG&nbsp;139, MEG&nbsp;140, MEG&nbsp;141, MEG&nbsp;142, MEG&nbsp;143, MEG&nbsp;144, MEG&nbsp;145, MEG&nbsp;148, MEG&nbsp;149, MEG&nbsp;150, MEG&nbsp;151, MEG&nbsp;152, MEG&nbsp;153, MEG&nbsp;154, MEG&nbsp;155, MEG&nbsp;156, MEG&nbsp;157')\" title=\"(Click to open in popup)&#13;&#13;MEG&nbsp;001, MEG&nbsp;002, MEG&nbsp;003, MEG&nbsp;005, MEG&nbsp;006, MEG&nbsp;007, MEG&nbsp;008, MEG&nbsp;009, MEG&nbsp;010, MEG&nbsp;011, MEG&nbsp;012, MEG&nbsp;013, MEG&nbsp;016, MEG&nbsp;017, MEG&nbsp;018, MEG&nbsp;019, MEG&nbsp;020, MEG&nbsp;021, MEG&nbsp;022, MEG&nbsp;023, MEG&nbsp;024, MEG&nbsp;025, MEG&nbsp;026, MEG&nbsp;027, MEG&nbsp;028, MEG&nbsp;029, MEG&nbsp;030, MEG&nbsp;031, MEG&nbsp;032, MEG&nbsp;033, MEG&nbsp;034, MEG&nbsp;035, MEG&nbsp;036, MEG&nbsp;037, MEG&nbsp;038, MEG&nbsp;039, MEG&nbsp;040, MEG&nbsp;041, MEG&nbsp;042, MEG&nbsp;043, MEG&nbsp;044, MEG&nbsp;045, MEG&nbsp;046, MEG&nbsp;047, MEG&nbsp;048, MEG&nbsp;049, MEG&nbsp;050, MEG&nbsp;051, MEG&nbsp;052, MEG&nbsp;053, MEG&nbsp;054, MEG&nbsp;055, MEG&nbsp;056, MEG&nbsp;057, MEG&nbsp;058, MEG&nbsp;059, MEG&nbsp;060, MEG&nbsp;061, MEG&nbsp;062, MEG&nbsp;063, MEG&nbsp;064, MEG&nbsp;065, MEG&nbsp;066, MEG&nbsp;067, MEG&nbsp;069, MEG&nbsp;070, MEG&nbsp;071, MEG&nbsp;072, MEG&nbsp;073, MEG&nbsp;074, MEG&nbsp;075, MEG&nbsp;076, MEG&nbsp;077, MEG&nbsp;078, MEG&nbsp;080, MEG&nbsp;081, MEG&nbsp;082, MEG&nbsp;083, MEG&nbsp;084, MEG&nbsp;085, MEG&nbsp;086, MEG&nbsp;087, MEG&nbsp;088, MEG&nbsp;089, MEG&nbsp;090, MEG&nbsp;091, MEG&nbsp;092, MEG&nbsp;093, MEG&nbsp;094, MEG&nbsp;095, MEG&nbsp;096, MEG&nbsp;097, MEG&nbsp;098, MEG&nbsp;099, MEG&nbsp;100, MEG&nbsp;101, MEG&nbsp;102, MEG&nbsp;103, MEG&nbsp;104, MEG&nbsp;105, MEG&nbsp;106, MEG&nbsp;107, MEG&nbsp;108, MEG&nbsp;109, MEG&nbsp;110, MEG&nbsp;111, MEG&nbsp;112, MEG&nbsp;113, MEG&nbsp;114, MEG&nbsp;115, MEG&nbsp;116, MEG&nbsp;117, MEG&nbsp;118, MEG&nbsp;119, MEG&nbsp;120, MEG&nbsp;121, MEG&nbsp;122, MEG&nbsp;123, MEG&nbsp;124, MEG&nbsp;125, MEG&nbsp;126, MEG&nbsp;127, MEG&nbsp;128, MEG&nbsp;129, MEG&nbsp;130, MEG&nbsp;131, MEG&nbsp;132, MEG&nbsp;133, MEG&nbsp;134, MEG&nbsp;135, MEG&nbsp;136, MEG&nbsp;137, MEG&nbsp;138, MEG&nbsp;139, MEG&nbsp;140, MEG&nbsp;141, MEG&nbsp;142, MEG&nbsp;143, MEG&nbsp;144, MEG&nbsp;145, MEG&nbsp;148, MEG&nbsp;149, MEG&nbsp;150, MEG&nbsp;151, MEG&nbsp;152, MEG&nbsp;153, MEG&nbsp;154, MEG&nbsp;155, MEG&nbsp;156, MEG&nbsp;157\">\n",
       "            150\n",
       "        </button>\n",
       "\n",
       "        \n",
       "        \n",
       "        and <button class=\"channel-names-btn\" onclick=\"alert('Bad Magnetometers:\\n\\nMEG&nbsp;004, MEG&nbsp;014, MEG&nbsp;015, MEG&nbsp;068, MEG&nbsp;079, MEG&nbsp;146, MEG&nbsp;147')\" title=\"(Click to open in popup)&#13;&#13;MEG&nbsp;004, MEG&nbsp;014, MEG&nbsp;015, MEG&nbsp;068, MEG&nbsp;079, MEG&nbsp;146, MEG&nbsp;147\">\n",
       "            7 bad\n",
       "        </button>\n",
       "        \n",
       "    </td>\n",
       "</tr>\n",
       "\n",
       "\n",
       "<tr class=\"repr-element channels-66805a13-fabb-461d-aba9-75e0d45ee18d \">\n",
       "    <td class=\"repr-section-toggle-col\"></td>\n",
       "    <td>misc</td>\n",
       "    <td>\n",
       "        <button class=\"channel-names-btn\" onclick=\"alert('Good misc:\\n\\nMISC&nbsp;001, MISC&nbsp;002, MISC&nbsp;003, MISC&nbsp;004, MISC&nbsp;005, MISC&nbsp;006, MISC&nbsp;007, MISC&nbsp;008, MISC&nbsp;009, MISC&nbsp;010, MISC&nbsp;011, MISC&nbsp;012, MISC&nbsp;013, MISC&nbsp;014, MISC&nbsp;015, MISC&nbsp;016, MISC&nbsp;017, MISC&nbsp;018, MISC&nbsp;019, MISC&nbsp;020, MISC&nbsp;021, MISC&nbsp;022, MISC&nbsp;023, MISC&nbsp;024, MISC&nbsp;025, MISC&nbsp;026, MISC&nbsp;027, MISC&nbsp;028, MISC&nbsp;029, MISC&nbsp;030, MISC&nbsp;031, MISC&nbsp;032')\" title=\"(Click to open in popup)&#13;&#13;MISC&nbsp;001, MISC&nbsp;002, MISC&nbsp;003, MISC&nbsp;004, MISC&nbsp;005, MISC&nbsp;006, MISC&nbsp;007, MISC&nbsp;008, MISC&nbsp;009, MISC&nbsp;010, MISC&nbsp;011, MISC&nbsp;012, MISC&nbsp;013, MISC&nbsp;014, MISC&nbsp;015, MISC&nbsp;016, MISC&nbsp;017, MISC&nbsp;018, MISC&nbsp;019, MISC&nbsp;020, MISC&nbsp;021, MISC&nbsp;022, MISC&nbsp;023, MISC&nbsp;024, MISC&nbsp;025, MISC&nbsp;026, MISC&nbsp;027, MISC&nbsp;028, MISC&nbsp;029, MISC&nbsp;030, MISC&nbsp;031, MISC&nbsp;032\">\n",
       "            32\n",
       "        </button>\n",
       "\n",
       "        \n",
       "    </td>\n",
       "</tr>\n",
       "\n",
       "\n",
       "<tr class=\"repr-element channels-66805a13-fabb-461d-aba9-75e0d45ee18d \">\n",
       "    <td class=\"repr-section-toggle-col\"></td>\n",
       "    <td>Reference Magnetometers</td>\n",
       "    <td>\n",
       "        <button class=\"channel-names-btn\" onclick=\"alert('Good Reference Magnetometers:\\n\\nMEG&nbsp;158, MEG&nbsp;159, MEG&nbsp;160')\" title=\"(Click to open in popup)&#13;&#13;MEG&nbsp;158, MEG&nbsp;159, MEG&nbsp;160\">\n",
       "            3\n",
       "        </button>\n",
       "\n",
       "        \n",
       "    </td>\n",
       "</tr>\n",
       "\n",
       "\n",
       "<tr class=\"repr-element channels-66805a13-fabb-461d-aba9-75e0d45ee18d \">\n",
       "    <td class=\"repr-section-toggle-col\"></td>\n",
       "    <td>Stimulus</td>\n",
       "    <td>\n",
       "        <button class=\"channel-names-btn\" onclick=\"alert('Good Stimulus:\\n\\nSTI&nbsp;014')\" title=\"(Click to open in popup)&#13;&#13;STI&nbsp;014\">\n",
       "            1\n",
       "        </button>\n",
       "\n",
       "        \n",
       "    </td>\n",
       "</tr>\n",
       "\n",
       "\n",
       "<tr class=\"repr-element channels-66805a13-fabb-461d-aba9-75e0d45ee18d \">\n",
       "    <td class=\"repr-section-toggle-col\"></td>\n",
       "    <td>Head & sensor digitization</td>\n",
       "    \n",
       "    <td>3681 points</td>\n",
       "    \n",
       "</tr>\n",
       "    \n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "<tr class=\"repr-section-header filters-6b4506a4-e6ef-4922-bb87-94706a128c9c\"  title=\"Hide section\" \n",
       "    onclick=\"toggleVisibility('filters-6b4506a4-e6ef-4922-bb87-94706a128c9c')\">\n",
       "    <th class=\"repr-section-toggle-col\">\n",
       "        <button>\n",
       "            \n",
       "            <span class=\"collapse-uncollapse-caret\"></span>\n",
       "        </button>\n",
       "    </th>\n",
       "    <th colspan=\"2\">\n",
       "        <strong>Filters</strong>\n",
       "    </th>\n",
       "</tr>\n",
       "\n",
       "<tr class=\"repr-element filters-6b4506a4-e6ef-4922-bb87-94706a128c9c \">\n",
       "    <td class=\"repr-section-toggle-col\"></td>\n",
       "    <td>Highpass</td>\n",
       "    <td>1.00 Hz</td>\n",
       "</tr>\n",
       "\n",
       "\n",
       "<tr class=\"repr-element filters-6b4506a4-e6ef-4922-bb87-94706a128c9c \">\n",
       "    <td class=\"repr-section-toggle-col\"></td>\n",
       "    <td>Lowpass</td>\n",
       "    <td>40.00 Hz</td>\n",
       "</tr>\n",
       "\n",
       "\n",
       "</table>"
      ],
      "text/plain": [
       "<Raw | R2487_loc.fif, 193 x 89000 (890.0 s), ~132.7 MB, data loaded>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# raw = mne.io.read_raw_fif('data_meg/R2490/prepro/R2490_exp.fif', preload='temp_raw.fif')\n",
    "raw = mne.io.read_raw_fif(f'{data_dir}/{subj}/{dataqual}/{subj}_{exp}.fif', preload=True)\n",
    "raw.info['bads'].extend(bad_channels)\n",
    "sfreq = raw.info['sfreq']\n",
    "raw.filter(1, 40, method='iir')\n",
    "downsample = 10\n",
    "raw.resample(sfreq / downsample)\n",
    "# raw.drop_channels(bad_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 projection items deactivated\n",
      "Using up to 900 segments\n",
      "Number of samples used : 180000\n",
      "[done]\n"
     ]
    }
   ],
   "source": [
    "raw_empty_room.info[\"bads\"] = [bb for bb in raw.info[\"bads\"] if \"MEG\" not in bb]\n",
    "raw_empty_room.add_proj(\n",
    "    [pp.copy() for pp in raw.info[\"projs\"] if \"MEG\" not in pp[\"desc\"]]\n",
    ")\n",
    "\n",
    "noise_cov = mne.compute_raw_covariance(raw_empty_room, tmin=0, tmax=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254 events found on stim channel STI 014\n",
      "Event IDs: [164 165]\n"
     ]
    }
   ],
   "source": [
    "events = mne.find_events(raw, stim_channel='STI 014', output='onset', shortest_event=1)\n",
    "event_id = {\n",
    "    'start': 160,\n",
    "    'move': 161,\n",
    "    'reveal_red': 162,\n",
    "    'reveal_white': 163,\n",
    "    'done': 164,\n",
    "    'choice': 165,\n",
    "    'timeout': 166\n",
    "}\n",
    "\n",
    "start_events = events[events[:, 2] == event_id['start']]\n",
    "done_events = events[events[:, 2] == event_id['done']] \n",
    "timeout_events = events[events[:, 2] == event_id['timeout']]\n",
    "choice_events = events[events[:, 2] == event_id['choice']]\n",
    "sfreq = raw.info['sfreq']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Less than 3 seconds between done events at indices 37 and 38\n",
      "Filtered done events count: 121\n"
     ]
    }
   ],
   "source": [
    "if subj == \"R2488\" :\n",
    "    done_events = done_events[1:]\n",
    "# Initialize a list to store filtered done events\n",
    "filtered_done_events = [done_events[0]]  # Start with the first event\n",
    "\n",
    "# Check for at least 3 seconds between each done event\n",
    "for i in range(1, len(done_events)):\n",
    "    time_diff = (done_events[i, 0] - done_events[i-1, 0]) / sfreq\n",
    "    if time_diff < 2:\n",
    "        print(f\"Warning: Less than 3 seconds between done events at indices {i-1} and {i}\")\n",
    "    \n",
    "    else:\n",
    "        filtered_done_events.append(done_events[i])\n",
    "done_events = filtered_done_events\n",
    "done_events = done_events[-120:]\n",
    "# Use filtered_done_events for further processing\n",
    "print(f\"Filtered done events count: {len(filtered_done_events)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "choice_events = events[events[:, 2] == event_id['choice']]\n",
    "start_events = np.array([[done_event[0] - int(3 * sfreq), 0, event_id['start']] for done_event in done_events])\n",
    "# start_events = events[events[:, 2] == event_id['start']]\n",
    "# start_events = start_events[-120:]\n",
    "sfreq = raw.info['sfreq']  # Sampling frequency\n",
    "\n",
    "\n",
    "# Initialize a list to store trial information\n",
    "trial_info = []\n",
    "start_idx = 0\n",
    "\n",
    "# Iterate through each reconstructed start event to create trial information\n",
    "for start_event, done_event in zip(start_events, done_events):\n",
    "    start_sample = start_event[0]\n",
    "    done_sample = done_event[0]\n",
    "    # done_sample = start_sample + int(3.4 * sfreq)\n",
    "    # Calculate tmin and tmax for the epoch\n",
    "    tmin = -0.2  # 0.2 s before 'start'\n",
    "    tmax = (done_sample - start_sample) / sfreq  # Duration from 'start' to 'done'\n",
    "    # Find choice events within the trial\n",
    "    choice_event = choice_events[(choice_events[:, 0] > start_sample) & \n",
    "                                 (choice_events[:, 0] < done_sample + int(0.5*sfreq))]\n",
    "    choice_time = choice_event[-1, 0] if len(choice_event) > 0 else None\n",
    "    \n",
    "    # Store trial information\n",
    "    trial_info.append({\n",
    "        'event_sample': done_sample,\n",
    "        'trial_index': start_idx,\n",
    "        'duration': tmax,\n",
    "        'tmin': tmin,\n",
    "        'tmax': tmax,\n",
    "        'done': len(done_events) > 0,\n",
    "        'done_times': done_sample / sfreq,\n",
    "        'start_times': start_sample / sfreq,\n",
    "        'choice_event': len(choice_event) > 0,\n",
    "        'choice_time': choice_time / sfreq if len(choice_event) > 0 else None\n",
    "    })\n",
    "    start_idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2781.0 3081.0\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "3272.9999999999995 3572.9999999999995\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "3765.0 4065.0\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "4259.0 4559.0\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "4752.0 5052.0\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "5245.0 5545.0\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "5737.0 6037.0\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "6230.0 6530.0\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "6723.999999999999 7023.999999999999\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "7219.0 7519.0\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "7712.0 8012.0\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "8204.0 8504.0\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "8697.0 8997.0\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "9190.0 9490.0\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "9683.0 9983.0\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "10177.0 10477.0\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "10670.0 10970.0\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "11163.0 11463.0\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "11656.0 11956.0\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "12148.0 12448.0\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "12642.0 12941.999999999998\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "13135.0 13435.0\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "13629.0 13929.0\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "14121.0 14421.0\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "14613.0 14913.0\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "15106.0 15406.0\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "15601.0 15901.0\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "16096.0 16396.0\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "16588.0 16888.0\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "21693.0 21993.0\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "22185.0 22485.0\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "22677.0 22977.0\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "23171.0 23471.0\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "23666.0 23966.0\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "24158.0 24458.0\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "24650.0 24950.0\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "25144.0 25444.0\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "25645.999999999996 25945.999999999996\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "26141.000000000004 26441.000000000004\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "26633.999999999996 26933.999999999996\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "27127.0 27427.0\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "27622.000000000004 27922.000000000004\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "28114.999999999996 28414.999999999996\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "28608.0 28908.0\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "29100.0 29400.0\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "29594.0 29894.0\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "30087.0 30387.0\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "30581.0 30881.0\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "31073.0 31373.0\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "31567.0 31867.0\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "32062.0 32362.0\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "32557.0 32857.0\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "33050.0 33350.0\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "33543.0 33843.0\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "34037.0 34337.0\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "34530.0 34830.0\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "35053.0 35353.0\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "35545.0 35845.0\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "36038.0 36338.0\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "48564.0 48864.0\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "57903.0 58203.0\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "58401.0 58701.0\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "58892.99999999999 59192.99999999999\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "59387.0 59687.0\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "59879.99999999999 60179.99999999999\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "60373.0 60673.0\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "60866.0 61166.0\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "61360.0 61660.0\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "61853.0 62153.0\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "62346.0 62646.0\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "62839.0 63139.0\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "63333.00000000001 63633.00000000001\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "63826.0 64126.0\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "64320.00000000001 64620.00000000001\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "64814.0 65114.0\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "65309.0 65609.0\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "65804.0 66104.0\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "66298.0 66598.0\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "66792.0 67092.0\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "67286.0 67586.0\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "67779.0 68079.0\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "68273.0 68573.0\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "68767.0 69067.0\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "69259.0 69559.0\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "69753.0 70053.0\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "70246.0 70546.0\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "70738.0 71038.0\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "71232.0 71532.0\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "71726.0 72026.0\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "72219.0 72519.0\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "73660.0 73960.0\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "74155.0 74455.0\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "74650.0 74950.0\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "75143.0 75443.0\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "75637.0 75937.0\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "76130.0 76430.0\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "76624.0 76924.0\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "77118.0 77418.0\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "77610.0 77910.0\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "78104.0 78404.0\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "78597.0 78897.0\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "79089.0 79389.0\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "79581.0 79881.0\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "80075.0 80375.0\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "80570.0 80870.0\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "81062.0 81362.0\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "81554.0 81854.0\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "82048.0 82348.0\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "82541.0 82841.0\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "83035.0 83335.0\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "83528.0 83828.0\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "84020.0 84320.0\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "84513.0 84813.0\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "85006.0 85306.0\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "85499.0 85799.0\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "85993.0 86293.0\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "86486.0 86786.0\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "86980.0 87280.0\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "87472.0 87772.0\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n",
      "87964.0 88264.0\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1 events and 171 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    }
   ],
   "source": [
    "# Use the trial information to create epochs\n",
    "picks = mne.pick_types(raw.info, meg=True, exclude='bads')\n",
    "data_list = []\n",
    "for info in trial_info:\n",
    "    start_sample = info['start_times'] * sfreq\n",
    "    done_sample = info['done_times'] * sfreq\n",
    "    tmin = -0.2 # 0.2 s before 'start'\n",
    "    tmax = 1.5  # Duration from 'start' to 'done'\n",
    "    print(start_sample, done_sample)\n",
    "    event = [int(start_sample), 0, event_id['start']]\n",
    "    epochs = mne.Epochs(\n",
    "        raw, [event], event_id={'start': event_id['start']},\n",
    "        tmin=tmin, tmax=tmax, preload=True, picks=picks,\n",
    "        reject_by_annotation=False, reject=None, verbose=True\n",
    "    )\n",
    "    data_list.append(epochs.get_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reducing data rank from 150 -> 150\n",
      "Estimating covariance using PCA\n",
      "... rank: 5 - loglik: -890.301\n",
      "... rank: 10 - loglik: -1030.291\n",
      "... infinite values encountered. stopping estimation\n",
      "... best model at rank = 5\n",
      "Done.\n",
      "Number of samples used : 21\n",
      "[done]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/79/m99pb_8d67l3d79st4zhf4tc0000gn/T/ipykernel_56589/2898505299.py:1: RuntimeWarning: Too few samples (required : 755 got : 21), covariance estimate may be unreliable\n",
      "  noise_cov_reg = mne.compute_covariance(epochs, tmax=0.0, method=\"pca\", rank=\"full\")\n"
     ]
    }
   ],
   "source": [
    "noise_cov_reg = mne.compute_covariance(epochs, tmax=0.0, method=\"pca\", rank=\"full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_events = np.array([[info['event_sample'], 0, event_id['done']] for info in trial_info])\n",
    "# choice_events = np.array([[info['event_sample'], 0, event_id['choice']] for info in trial_info])\n",
    "\n",
    "# # Initialize lists to store individual epochs data and trial information\n",
    "# data_list = []\n",
    "\n",
    "# for idx, event in enumerate(new_events):\n",
    "#     choice_time = info['choice_time']  # Retrieve choice_time for the current trial\n",
    "#     if choice_time is not None:\n",
    "#         start_sample = int(choice_time * sfreq)  # Convert choice_time to sample index\n",
    "#         tmin = -0.5  # 0.5 s before 'choice'\n",
    "#         tmax = 0.5  # 0.5 s after 'choice'\n",
    "#     else:\n",
    "#         start_sample = int(info['done_times'] * sfreq)  # Use done time if choice_time is not available\n",
    "#         tmin = -3.5  # 1 s before 'done'\n",
    "#         tmax = 0.1 # At 'done'\n",
    "    \n",
    "#     event_id_code = event_id['choice'] if choice_time is not None else event_id['done']\n",
    "#     event = [start_sample, 0, event_id_code]\n",
    "#     picks = mne.pick_types(raw.info, meg=True, exclude='bads')\n",
    "\n",
    "#     epochs = mne.Epochs(\n",
    "#         raw, [event], event_id={f'event_{event_id_code}': event_id_code},\n",
    "#         tmin=tmin, tmax=tmax, preload=True, picks=picks,\n",
    "#         reject_by_annotation=False, reject=None, verbose=True\n",
    "#     )\n",
    "#     data_list.append(epochs.get_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    }
   ],
   "source": [
    "print(len(data_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from mne.decoding import SlidingEstimator, cross_val_multiscore, Vectorizer, GeneralizingEstimator\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "import joblib  # For saving the model\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the pipeline\n",
    "pipe = Pipeline([\n",
    "    (\"scale\", StandardScaler()),              # Scale the features\n",
    "    (\"reduce_dims\", PCA()),                   # Apply PCA\n",
    "    (\"ridge\", Ridge())                        # Ridge Regression\n",
    "])\n",
    "\n",
    "# Define the grid of hyperparameters\n",
    "param_grid = {\n",
    "    \"reduce_dims__n_components\": [0.5, 0.75, 0.95],  # Retain 50%, 75%, or 95% variance\n",
    "    \"ridge__alpha\": np.logspace(-5, 5, 10),          # Regularization strength\n",
    "    \"ridge__fit_intercept\": [True, False],           # Fit intercept or not\n",
    "}\n",
    "\n",
    "# Set up GridSearchCV\n",
    "grid = GridSearchCV(pipe, param_grid=param_grid, cv=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(171, 18000) (171,)\n"
     ]
    }
   ],
   "source": [
    "X = np.array([md.data for md in data_list])  # Ensure this is 3D\n",
    "X = X.squeeze(axis=1)\n",
    "X_reshaped = X.transpose(2, 0, 1).reshape(171, -1) \n",
    "y = np.array([0 if t < 0 else 1 for t in epochs.times])\n",
    "print(X_reshaped.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[124], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mgrid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_reshaped\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Get the best model\u001b[39;00m\n\u001b[1;32m      3\u001b[0m best_model \u001b[38;5;241m=\u001b[39m grid\u001b[38;5;241m.\u001b[39mbest_estimator_\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/meg/lib/python3.9/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/meg/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1019\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m   1014\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m   1015\u001b[0m     )\n\u001b[1;32m   1017\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m-> 1019\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1021\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m   1022\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m   1023\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/meg/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1573\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1571\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1572\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1573\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/meg/lib/python3.9/site-packages/sklearn/model_selection/_search.py:965\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    957\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    958\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    959\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    960\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    961\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    962\u001b[0m         )\n\u001b[1;32m    963\u001b[0m     )\n\u001b[0;32m--> 965\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    966\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    967\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    968\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    981\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    984\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    985\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    986\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    987\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    988\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/meg/lib/python3.9/site-packages/sklearn/utils/parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     73\u001b[0m )\n\u001b[0;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/meg/lib/python3.9/site-packages/joblib/parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/meg/lib/python3.9/site-packages/joblib/parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/meg/lib/python3.9/site-packages/sklearn/utils/parallel.py:136\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/meg/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:888\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    886\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m    887\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 888\u001b[0m         \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    891\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    892\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/meg/lib/python3.9/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/meg/lib/python3.9/site-packages/sklearn/pipeline.py:469\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model.\u001b[39;00m\n\u001b[1;32m    427\u001b[0m \n\u001b[1;32m    428\u001b[0m \u001b[38;5;124;03mFit all the transformers one after the other and sequentially transform the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;124;03m    Pipeline with fitted steps.\u001b[39;00m\n\u001b[1;32m    467\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    468\u001b[0m routed_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_method_params(method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m, props\u001b[38;5;241m=\u001b[39mparams)\n\u001b[0;32m--> 469\u001b[0m Xt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    470\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_message(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)):\n\u001b[1;32m    471\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/meg/lib/python3.9/site-packages/sklearn/pipeline.py:406\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[0;34m(self, X, y, routed_params)\u001b[0m\n\u001b[1;32m    404\u001b[0m     cloned_transformer \u001b[38;5;241m=\u001b[39m clone(transformer)\n\u001b[1;32m    405\u001b[0m \u001b[38;5;66;03m# Fit or load from cache the current transformer\u001b[39;00m\n\u001b[0;32m--> 406\u001b[0m X, fitted_transformer \u001b[38;5;241m=\u001b[39m \u001b[43mfit_transform_one_cached\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcloned_transformer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessage_clsname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPipeline\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_log_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_idx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;66;03m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;66;03m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;66;03m# from the cache.\u001b[39;00m\n\u001b[1;32m    418\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[step_idx] \u001b[38;5;241m=\u001b[39m (name, fitted_transformer)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/meg/lib/python3.9/site-packages/joblib/memory.py:312\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 312\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/meg/lib/python3.9/site-packages/sklearn/pipeline.py:1310\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, params)\u001b[0m\n\u001b[1;32m   1308\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[1;32m   1309\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(transformer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_transform\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1310\u001b[0m         res \u001b[38;5;241m=\u001b[39m \u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfit_transform\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1311\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1312\u001b[0m         res \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m, {}))\u001b[38;5;241m.\u001b[39mtransform(\n\u001b[1;32m   1313\u001b[0m             X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransform\u001b[39m\u001b[38;5;124m\"\u001b[39m, {})\n\u001b[1;32m   1314\u001b[0m         )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/meg/lib/python3.9/site-packages/sklearn/utils/_set_output.py:316\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 316\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    318\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    319\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    320\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    321\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    322\u001b[0m         )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/meg/lib/python3.9/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/meg/lib/python3.9/site-packages/sklearn/decomposition/_pca.py:474\u001b[0m, in \u001b[0;36mPCA.fit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_transform\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    453\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model with X and apply the dimensionality reduction on X.\u001b[39;00m\n\u001b[1;32m    454\u001b[0m \n\u001b[1;32m    455\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    472\u001b[0m \u001b[38;5;124;03m    C-ordered array, use 'np.ascontiguousarray'.\u001b[39;00m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 474\u001b[0m     U, S, _, X, x_is_centered, xp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    475\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m U \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    476\u001b[0m         U \u001b[38;5;241m=\u001b[39m U[:, : \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_components_]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/meg/lib/python3.9/site-packages/sklearn/decomposition/_pca.py:547\u001b[0m, in \u001b[0;36mPCA._fit\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    545\u001b[0m \u001b[38;5;66;03m# Call different fits for either full or truncated SVD\u001b[39;00m\n\u001b[1;32m    546\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_svd_solver \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfull\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcovariance_eigh\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 547\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_full\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_components\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_array_api_compliant\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    548\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_svd_solver \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marpack\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrandomized\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    549\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_truncated(X, n_components, xp)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/meg/lib/python3.9/site-packages/sklearn/decomposition/_pca.py:588\u001b[0m, in \u001b[0;36mPCA._fit_full\u001b[0;34m(self, X, n_components, xp, is_array_api_compliant)\u001b[0m\n\u001b[1;32m    578\u001b[0m x_is_centered \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy\n\u001b[1;32m    580\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_array_api_compliant:\n\u001b[1;32m    581\u001b[0m     \u001b[38;5;66;03m# Use scipy.linalg with NumPy/SciPy inputs for the sake of not\u001b[39;00m\n\u001b[1;32m    582\u001b[0m     \u001b[38;5;66;03m# introducing unanticipated behavior changes. In the long run we\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;66;03m# solver by default though (assuming both are built against the\u001b[39;00m\n\u001b[1;32m    587\u001b[0m     \u001b[38;5;66;03m# same BLAS).\u001b[39;00m\n\u001b[0;32m--> 588\u001b[0m     U, S, Vt \u001b[38;5;241m=\u001b[39m \u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msvd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_centered\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_matrices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    589\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    590\u001b[0m     U, S, Vt \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39msvd(X_centered, full_matrices\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/meg/lib/python3.9/site-packages/scipy/linalg/_decomp_svd.py:141\u001b[0m, in \u001b[0;36msvd\u001b[0;34m(a, full_matrices, compute_uv, overwrite_a, check_finite, lapack_driver)\u001b[0m\n\u001b[1;32m    137\u001b[0m lwork \u001b[38;5;241m=\u001b[39m _compute_lwork(gesXd_lwork, a1\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], a1\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m    138\u001b[0m                        compute_uv\u001b[38;5;241m=\u001b[39mcompute_uv, full_matrices\u001b[38;5;241m=\u001b[39mfull_matrices)\n\u001b[1;32m    140\u001b[0m \u001b[38;5;66;03m# perform decomposition\u001b[39;00m\n\u001b[0;32m--> 141\u001b[0m u, s, v, info \u001b[38;5;241m=\u001b[39m \u001b[43mgesXd\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompute_uv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompute_uv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlwork\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlwork\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mfull_matrices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfull_matrices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverwrite_a\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverwrite_a\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m info \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LinAlgError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSVD did not converge\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "grid.fit(X_reshaped, y)\n",
    "# Get the best model\n",
    "best_model = grid.best_estimator_\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = grid.best_params_\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "# Get the best cross-validation score\n",
    "best_score = grid.best_score_\n",
    "print(f\"Best Cross-Validation Score: {best_score:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "y_pred = grid.best_estimator_.predict(X_reshaped)\n",
    "accuracy = (y == y_pred).mean()\n",
    "print(accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming X is your feature matrix with shape (n_epochs, n_channels, n_times)\n",
    "X = np.array([md.data for md in data_list])  # Ensure this is 3D\n",
    "X = X.squeeze(axis=1)  # This might reduce dimensions, ensure it's still 3D\n",
    "\n",
    "# Load the CSV file\n",
    "locolizer = pd.read_csv(f'{label_dir}/{subj}/loc_data.csv')\n",
    "\n",
    "# Extract valid trial indices\n",
    "valid_trial_indices = {info['trial_index'] for info in trial_info}\n",
    "\n",
    "# Extract labels and group information\n",
    "rule_label = locolizer.loc[locolizer['trial_index'].isin(valid_trial_indices), 'rule'].values\n",
    "group_start = locolizer.loc[locolizer['trial_index'].isin(valid_trial_indices), 'num_start'].values\n",
    "y = np.array(group_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group: greater_than_15, X_group shape: (60, 150, 321)\n",
      "Group: smaller_than_15, X_group shape: (60, 150, 321)\n"
     ]
    }
   ],
   "source": [
    "# Assuming X is your feature matrix with shape (n_epochs, n_channels, n_times)\n",
    "X = np.array([md.data for md in data_list])  # Ensure this is 3D\n",
    "X = X.squeeze(axis=1)  # This might reduce dimensions, ensure it's still 3D\n",
    "\n",
    "# Load the CSV file\n",
    "locolizer = pd.read_csv(f'{label_dir}/{subj}/loc_data.csv')\n",
    "\n",
    "# Extract valid trial indices\n",
    "valid_trial_indices = {info['trial_index'] for info in trial_info}\n",
    "\n",
    "# Extract labels and group information\n",
    "rule_label = locolizer.loc[locolizer['trial_index'].isin(valid_trial_indices), 'rule'].values\n",
    "group_start = locolizer.loc[locolizer['trial_index'].isin(valid_trial_indices), 'num_start'].values\n",
    "y = np.array(group_start)\n",
    "\n",
    "# Identify unique group_start labels\n",
    "unique_groups = np.unique(group_start)\n",
    "n_classes = len(unique_groups)\n",
    "\n",
    "\n",
    "def flatten_data(X):\n",
    "    n_samples, n_channels, n_timepoints = X.shape\n",
    "    print(n_samples, n_channels, n_timepoints)\n",
    "    return X.reshape(n_samples, n_channels * n_timepoints)\n",
    "\n",
    "def smooth_scores(scores, sigma=2):\n",
    "    return gaussian_filter1d(scores, sigma=sigma)\n",
    "\n",
    "def plot_time_decoding(scores_mean,title, subj):\n",
    "    n_time_points = scores_mean.shape[0]\n",
    "\n",
    "    plt.plot(np.arange(n_time_points), scores_mean)\n",
    "    plt.ylim(0, 0.6)\n",
    "    plt.xlim(0, 100)\n",
    "    plt.axhline(1/n_classes, color='k', linestyle='--', label='chance')\n",
    "    plt.axvline(20, color='k', linestyle='--')\n",
    "    plt.xlabel('Time Points')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.suptitle(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Define the two groups based on a new threshold value\n",
    "threshold = 15\n",
    "group_data = {'greater_than_15': [], 'smaller_than_15': []}\n",
    "group_labels = {'greater_than_15': [], 'smaller_than_15': []}\n",
    "\n",
    "# Populate group_data and group_labels based on the new threshold\n",
    "for idx, info in enumerate(trial_info):\n",
    "    trial_index = info['trial_index']\n",
    "    if trial_index in valid_trial_indices:\n",
    "        group_value = group_start[idx]  # Assuming group_start is the feature to be compared\n",
    "        if group_value > threshold:\n",
    "            group = 'greater_than_15'\n",
    "        else:\n",
    "            group = 'smaller_than_15'\n",
    "        \n",
    "        # Ensure the group is correctly assigned\n",
    "        if group in group_data:\n",
    "            group_data[group].append(X[idx])  # Ensure X[idx] is 3D\n",
    "            group_labels[group].append(rule_label[idx])\n",
    "        else:\n",
    "            print(f\"Unexpected group value: {group_value}\")\n",
    "\n",
    "\n",
    "\n",
    "# Train and evaluate the model for each group\n",
    "for group in ['greater_than_15', 'smaller_than_15']:\n",
    "    X_group = np.array(group_data[group])\n",
    "    y_group = np.array(group_labels[group])\n",
    "    \n",
    "    # Debugging: Check the shape of X_group\n",
    "    print(f\"Group: {group}, X_group shape: {X_group.shape}\")\n",
    "    \n",
    "    # cv = LeaveOneOut()\n",
    "    \n",
    "    # # Train the decoder\n",
    "    # clf = make_pipeline(StandardScaler(), LogisticRegression(max_iter=1000))\n",
    "    # time_decoding = SlidingEstimator(clf, n_jobs=5, scoring='accuracy')\n",
    "\n",
    "    # scores = cross_val_multiscore(time_decoding, X_group, y_group, cv=cv, n_jobs=5)\n",
    "    # scores_mean = np.mean(scores, axis=0)\n",
    "    # plot_time_decoding(scores_mean, f'Time Decoding {group}', subj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'rule_label'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/envs/meg/lib/python3.9/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'rule_label'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[140], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StratifiedKFold\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Extract group_start as y_label\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m y_label \u001b[38;5;241m=\u001b[39m \u001b[43mlocolizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlocolizer\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrial_index\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalid_trial_indices\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrule_label\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Filter y_label to only include values 25 and 4\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# valid_indices = np.isin(y_label, [25, 4])\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# y_label_filtered = y_label[valid_indices]\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Ensure X is 3D and y_label is aligned with X\u001b[39;00m\n\u001b[1;32m     11\u001b[0m X \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([md\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;28;01mfor\u001b[39;00m md \u001b[38;5;129;01min\u001b[39;00m data_list])  \u001b[38;5;66;03m# Ensure this is 3D\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/meg/lib/python3.9/site-packages/pandas/core/indexing.py:1184\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1182\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_scalar_access(key):\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_value(\u001b[38;5;241m*\u001b[39mkey, takeable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_takeable)\n\u001b[0;32m-> 1184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_tuple\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1185\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1186\u001b[0m     \u001b[38;5;66;03m# we by definition only have the 0th axis\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m     axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/meg/lib/python3.9/site-packages/pandas/core/indexing.py:1368\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   1366\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m suppress(IndexingError):\n\u001b[1;32m   1367\u001b[0m     tup \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_ellipsis(tup)\n\u001b[0;32m-> 1368\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_lowerdim\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1370\u001b[0m \u001b[38;5;66;03m# no multi-index, so validate all of the indexers\u001b[39;00m\n\u001b[1;32m   1371\u001b[0m tup \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_tuple_indexer(tup)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/meg/lib/python3.9/site-packages/pandas/core/indexing.py:1065\u001b[0m, in \u001b[0;36m_LocationIndexer._getitem_lowerdim\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tup):\n\u001b[1;32m   1062\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_label_like(key):\n\u001b[1;32m   1063\u001b[0m         \u001b[38;5;66;03m# We don't need to check for tuples here because those are\u001b[39;00m\n\u001b[1;32m   1064\u001b[0m         \u001b[38;5;66;03m#  caught by the _is_nested_tuple_indexer check above.\u001b[39;00m\n\u001b[0;32m-> 1065\u001b[0m         section \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1067\u001b[0m         \u001b[38;5;66;03m# We should never have a scalar section here, because\u001b[39;00m\n\u001b[1;32m   1068\u001b[0m         \u001b[38;5;66;03m#  _getitem_lowerdim is only called after a check for\u001b[39;00m\n\u001b[1;32m   1069\u001b[0m         \u001b[38;5;66;03m#  is_scalar_access, which that would be.\u001b[39;00m\n\u001b[1;32m   1070\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m section\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim:\n\u001b[1;32m   1071\u001b[0m             \u001b[38;5;66;03m# we're in the middle of slicing through a MultiIndex\u001b[39;00m\n\u001b[1;32m   1072\u001b[0m             \u001b[38;5;66;03m# revise the key wrt to `section` by inserting an _NS\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/meg/lib/python3.9/site-packages/pandas/core/indexing.py:1431\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1429\u001b[0m \u001b[38;5;66;03m# fall thru to straight lookup\u001b[39;00m\n\u001b[1;32m   1430\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_key(key, axis)\n\u001b[0;32m-> 1431\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_label\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/meg/lib/python3.9/site-packages/pandas/core/indexing.py:1381\u001b[0m, in \u001b[0;36m_LocIndexer._get_label\u001b[0;34m(self, label, axis)\u001b[0m\n\u001b[1;32m   1379\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_label\u001b[39m(\u001b[38;5;28mself\u001b[39m, label, axis: AxisInt):\n\u001b[1;32m   1380\u001b[0m     \u001b[38;5;66;03m# GH#5567 this will fail if the label is not present in the axis.\u001b[39;00m\n\u001b[0;32m-> 1381\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mxs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/meg/lib/python3.9/site-packages/pandas/core/generic.py:4287\u001b[0m, in \u001b[0;36mNDFrame.xs\u001b[0;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[1;32m   4285\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4286\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m drop_level:\n\u001b[0;32m-> 4287\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m   4288\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m   4289\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/meg/lib/python3.9/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/meg/lib/python3.9/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'rule_label'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Extract group_start as y_label\n",
    "y_label = locolizer.loc[locolizer['trial_index'].isin(valid_trial_indices), 'rule_label'].values\n",
    "\n",
    "# Filter y_label to only include values 25 and 4\n",
    "valid_indices = np.isin(y_label, [25, 4])\n",
    "y_label_filtered = y_label[valid_indices]\n",
    "\n",
    "# Ensure X is 3D and y_label is aligned with X\n",
    "X = np.array([md.data for md in data_list])  # Ensure this is 3D\n",
    "X = X.squeeze(axis=1)  # This might reduce dimensions, ensure it's still 3D\n",
    "\n",
    "# Filter X to correspond to the filtered y_label\n",
    "X_filtered = X[valid_indices]\n",
    "\n",
    "# Reshape X_filtered to 2D: (n_samples, n_features)\n",
    "n_samples, n_channels, n_timepoints = X_filtered.shape\n",
    "# X_reshaped = X_filtered.reshape(n_samples, n_channels * n_timepoints)\n",
    "\n",
    "print(f\"X shape: {X_filtered.shape}, y_label shape: {y_label_filtered.shape}\")\n",
    "# # Train and evaluate the model using group_start as y_label\n",
    "# cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# clf = make_pipeline(StandardScaler(), LogisticRegressionCV(max_iter=1000))\n",
    "# time_decoding = SlidingEstimator(clf, n_jobs=5, scoring='accuracy')\n",
    "\n",
    "# scores = cross_val_multiscore(time_decoding, X, y_label, cv=cv, n_jobs=5)\n",
    "# scores_mean = np.mean(scores, axis=0)\n",
    "# plot_time_decoding(scores_mean, 'Time Decoding using group_start', subj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X and y must have the same length.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[139], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m clf \u001b[38;5;241m=\u001b[39m make_pipeline(\n\u001b[1;32m      2\u001b[0m     StandardScaler(), LinearModel(LogisticRegression(solver\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlbfgs\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m      3\u001b[0m )\n\u001b[1;32m      4\u001b[0m time_decod \u001b[38;5;241m=\u001b[39m SlidingEstimator(clf, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 5\u001b[0m \u001b[43mtime_decod\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_filtered\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_label_filtered\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m coef \u001b[38;5;241m=\u001b[39m get_coef(time_decod, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpatterns_\u001b[39m\u001b[38;5;124m\"\u001b[39m, inverse_transform\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      8\u001b[0m coef_2d \u001b[38;5;241m=\u001b[39m coef\u001b[38;5;241m.\u001b[39mreshape(coef\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/meg/lib/python3.9/site-packages/mne/decoding/search_light.py:93\u001b[0m, in \u001b[0;36mSlidingEstimator.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params):\n\u001b[1;32m     74\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit a series of independent estimators to the dataset.\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \n\u001b[1;32m     76\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;124;03m        Return self.\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 93\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_Xy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m     parallel, p_func, n_jobs \u001b[38;5;241m=\u001b[39m parallel_func(\n\u001b[1;32m     95\u001b[0m         _sl_fit, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs, max_jobs\u001b[38;5;241m=\u001b[39mX\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     96\u001b[0m     )\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/meg/lib/python3.9/site-packages/mne/decoding/search_light.py:268\u001b[0m, in \u001b[0;36mSlidingEstimator._check_Xy\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    266\u001b[0m     y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(y)\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(X) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(y) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 268\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX and y must have the same length.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[1;32m    270\u001b[0m     err \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: X and y must have the same length."
     ]
    }
   ],
   "source": [
    "clf = make_pipeline(\n",
    "    StandardScaler(), LinearModel(LogisticRegression(solver=\"lbfgs\"))\n",
    ")\n",
    "time_decod = SlidingEstimator(clf, n_jobs=None, scoring=\"accuracy\", verbose=True)\n",
    "time_decod.fit(X_filtered, y_label_filtered)\n",
    "\n",
    "coef = get_coef(time_decod, \"patterns_\", inverse_transform=True)\n",
    "coef_2d = coef.reshape(coef.shape[0], -1)\n",
    "evoked_time_gen = mne.EvokedArray(coef_2d, epochs.info, tmin=epochs.times[0])\n",
    "\n",
    "joint_kwargs = dict(ts_args=dict(time_unit=\"s\"), topomap_args=dict(time_unit=\"s\"))\n",
    "evoked_time_gen.plot_joint(\n",
    "    times=np.arange(0.0, 0.500, 0.100), title=f\"Decoding rule {subj}\", **joint_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | Fitting SlidingEstimator : 0/221 [00:00<?,       ?it/s]/Users/dorisyu/opt/anaconda3/envs/meg/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "100%|| Fitting SlidingEstimator : 221/221 [00:38<00:00,    5.72it/s]\n",
      "100%|| Fitting SlidingEstimator : 221/221 [00:23<00:00,    9.21it/s]\n",
      "100%|| Fitting SlidingEstimator : 221/221 [00:24<00:00,    9.20it/s]\n",
      "100%|| Fitting SlidingEstimator : 221/221 [00:23<00:00,    9.51it/s]\n",
      "100%|| Fitting SlidingEstimator : 221/221 [00:26<00:00,    8.47it/s]\n",
      "100%|| Fitting SlidingEstimator : 221/221 [00:23<00:00,    9.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5188536953242836\n"
     ]
    }
   ],
   "source": [
    "clf = make_pipeline(\n",
    "    StandardScaler(),                      # Standardize the features\n",
    "    PCA(n_components=0.95),                # Retain 95% of explained variance\n",
    "    LinearModel(LogisticRegressionCV(solver=\"lbfgs\", max_iter=1000))  # Logistic regression\n",
    ")\n",
    "\n",
    "time_decod = SlidingEstimator(clf, n_jobs=None, scoring=\"accuracy\", verbose=True)\n",
    "time_decod.fit(X, y)\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scores = cross_val_multiscore(time_decod, X_filtered, y_label_filtered, cv=cv, n_jobs=None)\n",
    "\n",
    "# Mean scores across cross-validation splits\n",
    "scores = np.mean(scores, axis=0)\n",
    "mean_accuracy = scores.mean()\n",
    "print(mean_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_average_time_decoding_with_variance_and_binning(scores, title, subj, n_classes, bin_size=10):\n",
    "    # Read the data from the specified files\n",
    "    bin_size = 10\n",
    "    # Reshape and average every `bin_size` time points\n",
    "    n_time_points = scores.shape[0]\n",
    "    n_bins = n_time_points // bin_size\n",
    "    binned_mean = scores[:n_bins * bin_size].reshape(n_bins, bin_size).mean(axis=1)\n",
    "    binned_std = scores[:n_bins * bin_size].reshape(n_bins, bin_size).std(axis=1)\n",
    "    \n",
    "    # Plotting\n",
    "    time_points = np.arange(n_bins) * bin_size\n",
    "    \n",
    "    plt.plot(time_points, binned_mean, label='Mean Accuracy')\n",
    "    plt.fill_between(time_points, binned_mean - binned_std, binned_mean + binned_std, alpha=0.2, label='Variance')\n",
    "    plt.ylim(0, 1)\n",
    "    plt.axhline(1/2, color='k', linestyle='--', label='Chance')\n",
    "    plt.axvline(20, color='k', linestyle='--')\n",
    "    plt.xlabel('Time Points (binned)')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.suptitle(title)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = f'output/{subj}'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "np.save(f'{save_dir}/{subj}_group_start.npy', scores_mean)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
